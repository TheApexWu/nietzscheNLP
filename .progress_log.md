# Nietzsche Translation Project — Private Progress Log

> **Purpose**: Document decisions, structure, and learning for myself. Not for public consumption. Retain across Claude compactions.

---

## Session 1: Dec 26, 2025 — Project Bootstrap

### What We Built

```
nietzcheNLP/
├── .gitignore          # Excludes PDFs, extracted text, model cache
├── README.md           # Public-facing, minimal
├── requirements.txt    # Core deps: sentence-transformers, pymupdf, umap-learn
├── corpus/
│   └── aligned/        # JSON files with extracted aphorisms
├── src/
│   ├── extract.py      # PDF → text → aphorisms
│   ├── embed.py        # Text → E5 embeddings
│   ├── align.py        # (placeholder)
│   ├── analyze.py      # (placeholder)
│   └── visualize.py    # (placeholder)
├── notebooks/          # For exploration
└── outputs/
    ├── embeddings/     # .npy files
    └── visualizations/ # Plots for blog post
```

### Key Decisions Made

#### 1. PDF Extraction: PyMuPDF, No OCR Needed

**Research finding**: All 6 PDFs have text layers (Internet Archive digitization).

**Decision**: Use `fitz` (PyMuPDF) only. No pytesseract/OCR complexity.

**Why it matters**: Simpler pipeline, faster iteration. OCR would add ~30 lines of fallback code and system dependencies for no benefit.

**Code pattern**:
```python
doc = fitz.open(path)
text = "\n\n".join(page.get_text() for page in doc)
doc.close()
```

#### 2. Embedding Model: multilingual-e5-large

**Options considered**:
| Model | Dims | Tokens | Verdict |
|-------|------|--------|---------|
| LaBSE | 768 | 256 | Good but over-aligns translations |
| paraphrase-multilingual-mpnet | 768 | 128 | Token limit too short |
| **multilingual-e5-large** | 1024 | 512 | **Winner** — nuance + length |
| distiluse | 512 | 128 | Too weak |

**Why E5**:
- 1024 dimensions = more capacity for philosophical nuance
- 512 tokens = handles long Nietzsche sentences
- Trained on academic text (S2ORC)
- Asymmetric query/passage design fits "original vs translation"

**Key implementation detail**: E5 requires prefixes:
```python
"query: {german_text}"      # For source
"passage: {english_text}"   # For translations
```

#### 3. Aphorism Regex: Imperfect but Usable

**The challenge**: Each PDF has different formatting.

**Current regex**:
```python
pattern = r'(?:^|\n)\s*(\d{1,3})\s*\n(.+?)(?=\n\s*\d{1,3}\s*\n|$)'
```

**Results**:
- Hollingdale: 295/296 ✓
- Kaufmann: 292/296 ✓
- Norman: 275/296 ~
- Faber: 280/296 ~
- Zimmern: 252/296 (older formatting)
- German: 0/296 ✗ (different structure entirely)

**Decision**: Good enough for English-to-English comparison. Will fix German regex later.

**Learning**: Perfect extraction is a trap. Get 80% working, iterate.

#### 4. Analysis Strategy: English↔English First

**Reasoning**:
1. Cross-lingual comparison adds model-specific biases
2. English-to-English isolates translator interpretation
3. German→English is Phase 2 (fidelity analysis)

**Planned phases**:
```
Phase 1: Which translators agree with each other?
Phase 2: Who stays closest to German?
Phase 3: Which passages show highest divergence?
```

### What's NOT Working Yet

1. **German extraction**: Regex doesn't match Gutenberg formatting
2. **Alignment**: Only aphorisms present in ALL translations get aligned (~200ish)
3. **Visualization**: Not started
4. **Key term analysis**: Not started (tracking "Wille zur Macht" etc.)

### Next Steps (Priority Order)

1. [ ] Fix German regex OR manually align a subset
2. [ ] Run embed.py to get baseline similarity matrix
3. [ ] UMAP visualization of all aphorisms colored by translator
4. [ ] Identify high-variance passages (where translators diverge most)
5. [ ] Key term extraction and focused analysis

---

## Technical Patterns Learned

### Pattern: Hybrid Agent Strategy

Used Claude Code agents efficiently:
```
1. Scout agent (Explore) — map the landscape
2. Parallel specialist agents — PDF research + embedding research
3. Direct Claude — actual implementation
```

**Insight**: Don't use agents for code writing. Use them for research/exploration. Write code yourself (or with direct Claude).

### Pattern: Minimal Viable Extraction

Don't build the perfect pipeline. Build:
1. Something that runs
2. Something that produces output
3. Iterate from there

The regex isn't perfect. The alignment isn't complete. But we have data to work with.

### Pattern: Private vs Public Code

**Public (for HN/GitHub)**:
- Clean, simple, readable
- No comments explaining "why I did this"
- Just works

**Private (this log)**:
- Decisions documented
- Trade-offs explained
- Learning preserved

---

## Questions to Revisit

1. **Ground truth problem**: What does it mean for a translation to be "faithful"? Embeddings measure distance, not fidelity.

2. **Flattening concern**: Do embeddings collapse philosophical nuance? Need to test with known-different concepts.

3. **What's the finding?**: The blog post needs a hook. Current hypothesis: "philosophically loaded terms show more translator divergence than mundane passages."

---

## Commands Reference

```bash
# Extract all PDFs
python3 src/extract.py

# Generate embeddings (requires model download first time)
python3 src/embed.py

# Check extracted data
cat corpus/aligned/walter_kaufman.json | jq '.aphorisms[:3]'
```

---

## Session Notes

### Dec 26, 2025

- Started from empty repo
- Scaffolded structure with agent research
- All PDFs have text layers (no OCR needed)
- Wrote extract.py and embed.py
- German extraction not working (TODO)
- Ready to run first embedding pass

**Time spent**: ~1 hour
**Lines of code**: ~250 across 2 files
**Key insight**: The hard part isn't NLP, it's getting clean aligned data from messy PDFs.

---

### Dec 26, 2025 (cont.) — German Extraction Fixed

**Problem**: Generic regex didn't work on Gutenberg German PDF (got 0/296).

**Solution**: Wrote `src/extract_german.py` — specialized extractor with two methods:
1. Regex pattern matching
2. Split-based extraction (more robust)

**Result**: **296/296 aphorisms extracted** ✓

**Key aphorisms verified**:
- §1: "Der Wille zur Wahrheit..." (1430 chars)
- §146: "Wer mit Ungeheuern kämpft..." — the abyss quote (162 chars)
- §188: Tyranny against nature (4756 chars)
- §257: Aristocratic society (1959 chars)
- §259: "Life is appropriation" (2396 chars)
- §260: Master/slave morality — longest aphorism (8174 chars)
- §296: Final reflection (4846 chars)

**Learning**: Different PDFs need different extraction strategies. Generic one-size-fits-all fails. The split method (regex split then iterate pairs) is more robust than trying to capture everything in one regex.

**Code pattern** (robust extraction):
```python
# Split on pattern, then iterate pairs
parts = re.split(r'\n\s*(\d{1,3})\.\s*\n?', text)
# parts[0] = before first num
# parts[1] = num1, parts[2] = content1
# parts[3] = num2, parts[4] = content2, etc.
```

---

### Dec 26, 2025 (cont.) — First Embeddings Complete

**Alignment**: 231 aphorisms common to all 6 translations
- Bottleneck: Zimmern (252/296) — older PDF formatting

**Model choice**:
- E5-large: ~44 min/translator on CPU (unusable without GPU)
- MiniLM-L12: ~2 sec/translator on CPU ← **used this**
- Added `mode="fast"` vs `mode="accurate"` switch to embed.py

**First results** (pairwise cosine similarity):

| Pair | Similarity | Interpretation |
|------|------------|----------------|
| Kaufmann ↔ Hollingdale | 0.886 | Near-identical (both 1960s-70s academic) |
| Faber ↔ Hollingdale | 0.878 | Very close |
| German ↔ Hollingdale | 0.833 | **Closest to original** |
| German ↔ Norman | 0.798 | Furthest from original |
| Norman ↔ Zimmern | 0.806 | Most divergent English pair |

**Key finding**: Hollingdale is the semantic centroid — highest similarity with everyone including German. This suggests Hollingdale might be the most "literal" translator.

**Hypothesis forming**:
- Kaufmann/Hollingdale cluster = "academic faithful" school
- Norman = more interpretive/literary
- Zimmern = Victorian stylistic drift

**Next**: UMAP visualization to see if clusters emerge visually.

---

### Dec 26, 2025 (cont.) — Embedding Validity Analysis

**The question**: Do these embeddings actually capture Nietzsche's German?

**Tests run**:

| Test | Result | Interpretation |
|------|--------|----------------|
| Concept differentiation | ✓ | Model distinguishes Wille zur Macht vs Wahrheit (0.572) |
| Cross-lingual mapping | ✓ | Übermensch → overman (0.784) > superman (0.441) |
| Archaic spelling | ⚠️ | "Werth" ↔ "Wert" only 0.525 — systematic confounder |
| Sentence alignment | ✓ | BGE passages map to English at 0.74-0.77 |
| Context sensitivity | ✓ | Full sentences carry more meaning than bare terms |

**The Wittgensteinian problem**:
Embeddings encode "meaning as use" — but the model learned "use" from modern web text, not philosophical texts. This creates **conceptual flattening**: Nietzsche's precise distinctions projected into generic semantic space.

**What we're actually measuring**:
- Semantic similarity in **modern multilingual web-text space**
- NOT philosophical fidelity to Nietzsche's conceptual framework

**Why it's still useful**:
1. **Relative comparisons valid**: Ordinal rankings of translator similarity are meaningful
2. **High-variance passages are signals**: Where all translators diverge = philosophically loaded
3. **Stylistic fingerprints real**: Can classify translator from embedding = genuine signature

**Archaic spelling is a confounder**:
The Gutenberg German uses 19th-century orthography (giebt, Theil, Werth) that the model doesn't fully recognize as equivalent to modern spellings. This **inflates German↔English divergence** systematically.

**Mitigation**: Focus on English↔English comparisons first (no archaic spelling issue). Use German comparisons for relative ranking only, not absolute fidelity claims.

**Blog post framing**:
- Be honest about what embeddings measure
- Frame as "computational distant reading" not "translation quality judgment"
- The finding is the divergence pattern, not which translation is "best"

---

*Last updated: Dec 26, 2025*
*Next session: UMAP visualization, identify high-variance passages*
